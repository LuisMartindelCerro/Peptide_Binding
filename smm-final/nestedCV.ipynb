{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "535c355f-55cd-4398-a302-389971bc8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import math\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from scipy.stats import pearsonr\n",
    "from pprint import pprint\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "80e60548-3e76-46c1-b779-c990c86662a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the functions of smm_gradient_descent just once\n",
    "\n",
    "def encode(peptides, encoding_scheme, alphabet):\n",
    "    \n",
    "    encoded_peptides = []\n",
    "\n",
    "    for peptide in peptides:\n",
    "\n",
    "        encoded_peptide = []\n",
    "\n",
    "        for peptide_letter in peptide:\n",
    "\n",
    "            for alphabet_letter in alphabet:\n",
    "\n",
    "                encoded_peptide.append(encoding_scheme[peptide_letter][alphabet_letter])\n",
    "\n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        \n",
    "    return np.array(encoded_peptides)\n",
    "\n",
    "def gradient_descent(y_pred, y_target, peptide, weights, lamb_N, epsilon):\n",
    "    \n",
    "    # do is dE/dO\n",
    "    do = y_pred - y_target\n",
    "        \n",
    "    for i in range(0, len(weights)):\n",
    "        \n",
    "        de_dw_i = do * peptide[i] + (2 * lamb_N * weights[i] * peptide[i])\n",
    "\n",
    "        weights[i] -= epsilon * de_dw_i\n",
    "        \n",
    "def vector_to_matrix(vector, alphabet):\n",
    "    \n",
    "    rows = int(len(vector)/len(alphabet))\n",
    "    \n",
    "    matrix = [0] * rows\n",
    "    \n",
    "    offset = 0\n",
    "    \n",
    "    for i in range(0, rows):\n",
    "        \n",
    "        matrix[i] = {}\n",
    "        \n",
    "        for j in range(0, 20):\n",
    "            \n",
    "            matrix[i][alphabet[j]] = vector[j+offset] \n",
    "        \n",
    "        offset += len(alphabet)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def to_psi_blast(matrix):\n",
    "\n",
    "    # print to user\n",
    "    \n",
    "    header = [\"\", \"A\", \"R\", \"N\", \"D\", \"C\", \"Q\", \"E\", \"G\", \"H\", \"I\", \"L\", \"K\", \"M\", \"F\", \"P\", \"S\", \"T\", \"W\", \"Y\", \"V\"]\n",
    "\n",
    "    print('{:>4} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8}'.format(*header)) \n",
    "\n",
    "    letter_order = [\"A\", \"R\", \"N\", \"D\", \"C\", \"Q\", \"E\", \"G\", \"H\", \"I\", \"L\", \"K\", \"M\", \"F\", \"P\", \"S\", \"T\", \"W\", \"Y\", \"V\"]\n",
    "\n",
    "    for i, row in enumerate(matrix):\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        scores.append(str(i+1) + \" A\")\n",
    "\n",
    "        for letter in letter_order:\n",
    "\n",
    "            score = row[letter]\n",
    "\n",
    "            scores.append(round(score, 4))\n",
    "\n",
    "        print('{:>4} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8} {:>8}'.format(*scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20c5404b-c3b8-42f0-a3c2-d187149a49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the functions of pep2score just once\n",
    "def initialize_matrix(peptide_length, alphabet):\n",
    "\n",
    "    init_matrix = [0]*peptide_length\n",
    "\n",
    "    for i in range(0, peptide_length):\n",
    "\n",
    "        row = {}\n",
    "\n",
    "        for letter in alphabet: \n",
    "            row[letter] = 0.0\n",
    "\n",
    "        #fancy way:  row = dict( zip( alphabet, [0.0]*len(alphabet) ) )\n",
    "\n",
    "        init_matrix[i] = row\n",
    "        \n",
    "    return init_matrix\n",
    "\n",
    "def from_psi_blast(file_name):\n",
    "\n",
    "    f = open(file_name, \"r\")\n",
    "    \n",
    "    nline = 0\n",
    "    for line in f:\n",
    "    \n",
    "        sline = str.split( line )\n",
    "        \n",
    "        if nline == 0:\n",
    "        # recover alphabet\n",
    "            alphabet = [str]*len(sline)\n",
    "            for i in range(0, len(sline)):\n",
    "                alphabet[i] = sline[i]\n",
    "                \n",
    "            matrix = initialize_matrix(peptide_length, alphabet)\n",
    "        \n",
    "        else:\n",
    "            i = int(sline[0])\n",
    "            \n",
    "            for j in range(2,len(sline)):\n",
    "                matrix[i-1][alphabet[j-2]] = float(sline[j])\n",
    "                \n",
    "        nline+= 1\n",
    "            \n",
    "    return matrix\n",
    "\n",
    "def score_peptide(peptide, matrix):\n",
    "    acum = 0\n",
    "    for i in range(0, len(peptide)):\n",
    "        acum += matrix[i][peptide[i]]\n",
    "    return acum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "caa0981e-2590-43c8-942b-ad6a876386b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "RDIR = \"/home/luis_ubuntu/unixdir/Peptide_Binding/smm-final/\"\n",
    "DDIR = \"/home/luis_ubuntu/unixdir/Peptide_Binding/Data\"\n",
    "\n",
    "alleles = [\"A0101\"]\n",
    "lambdas = [0.02, 0.08, 0.1]\n",
    "epis = [0.01, 0.04]\n",
    "folds = range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e3f9fe91-ebcf-44bd-9234-8cb460f80dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pearson correlation calculator ---\n",
    "def pearson_from_pairs(pairs):\n",
    "    n = len(pairs)\n",
    "    if n == 0:\n",
    "        return 0.0, float(\"inf\")\n",
    "    \n",
    "    x = [p[0] for p in pairs]\n",
    "    y = [p[1] for p in pairs]\n",
    "    \n",
    "    x0 = sum(x) / n\n",
    "    y0 = sum(y) / n\n",
    "    \n",
    "    t = nx = ny = err = 0.0\n",
    "    for i in range(n):\n",
    "        dx = x[i] - x0\n",
    "        dy = y[i] - y0\n",
    "        t += dx * dy\n",
    "        nx += dx * dx\n",
    "        ny += dy * dy\n",
    "        err += (x[i] - y[i]) ** 2\n",
    "    \n",
    "    if nx * ny == 0:\n",
    "        pcc = 0.0\n",
    "    else:\n",
    "        pcc = t / math.sqrt(nx * ny)\n",
    "    \n",
    "    mse = err / n\n",
    "    return pcc, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b6c79b8d-41ee-4d14-a91a-584c41675510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_enter(dir_path):\n",
    "    path = Path(dir_path)\n",
    "    path.mkdir(exist_ok=True)\n",
    "    os.chdir(path)\n",
    "\n",
    "def concat_train_files(n_list, allele, DDIR, held_out_fold):\n",
    "    output_file = Path(f\"conc_f00{held_out_fold}\")\n",
    "    if output_file.exists():\n",
    "        return output_file  # Return existing file without rewriting\n",
    "    \n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for n in n_list:\n",
    "            file_path = Path(f\"{DDIR}/{allele}/c00{n}\")\n",
    "            with open(file_path) as infile:\n",
    "                outfile.writelines(infile.readlines())\n",
    "\n",
    "def run_training_and_evaluation(RDIR, train_file, eval_file, mat_file, pred_file, _lambda, _epsilon):\n",
    "    # Run training\n",
    "    if not Path(mat_file).exists():\n",
    "        with open(mat_file, \"w\") as fout:\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"python\", f\"{RDIR}/smm_gradient_descent.py\",\n",
    "                    \"-l\", str(_lambda),\n",
    "                    \"-epi\", str(_epsilon),\n",
    "                    \"-t\", train_file,\n",
    "                    \"-e\", eval_file\n",
    "                ],\n",
    "                stdout=fout,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                env={**os.environ, \"QT_QPA_PLATFORM\": \"offscreen\"}\n",
    "            )\n",
    "\n",
    "    # Run evaluation\n",
    "    if not Path(pred_file).exists():\n",
    "        with open(pred_file, \"w\") as fout:\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"python\", f\"{RDIR}/pep2score.py\",\n",
    "                    \"-mat\", mat_file,\n",
    "                    \"-f\", eval_file\n",
    "                ],\n",
    "                stdout=fout,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                env={**os.environ, \"QT_QPA_PLATFORM\": \"offscreen\"}\n",
    "            )\n",
    "\n",
    "def collect_outer_preds(allele):\n",
    "    preds = []\n",
    "    preds_for_file = []\n",
    "    for path in Path('.').rglob('*.outer_pred'):\n",
    "        with open(path) as pf:\n",
    "            for line in pf:\n",
    "                if \"#\" not in line and line.strip():\n",
    "                    try:\n",
    "                        parts = line.strip().split()\n",
    "                        preds_for_file.append(f\"{parts[0]} {parts[1]} {parts[2]}\\n\")\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "    # Save all collected predictions to a single file\n",
    "    output_file = Path(f\"{allele}_prediction\")\n",
    "    with open(output_file, \"w\") as out:\n",
    "        out.writelines(preds_for_file)\n",
    "    \n",
    "    print(f\"Saved {len(preds_for_file)} predictions to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3ad4cc93-bd71-4b1e-8118-d28a44c807f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0101; Outer validation set = 0, lambda = 0.02 epsilon = 0.01 PCC 0.59812 MSE 0.01912\n",
      "A0101; Outer validation set = 0, lambda = 0.02 epsilon = 0.04 PCC 0.56607 MSE 0.02066\n",
      "A0101; Outer validation set = 0, lambda = 0.08 epsilon = 0.01 PCC 0.59816 MSE 0.01911\n",
      "A0101; Outer validation set = 0, lambda = 0.08 epsilon = 0.04 PCC 0.56611 MSE 0.02066\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 50\u001b[0m\n\u001b[1;32m     46\u001b[0m train_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../conc_f00\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Run training and evalutation\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mrun_training_and_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRDIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pred_file) \u001b[38;5;28;01mas\u001b[39;00m pf:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m pf:\n",
      "Cell \u001b[0;32mIn[126], line 21\u001b[0m, in \u001b[0;36mrun_training_and_evaluation\u001b[0;34m(RDIR, train_file, eval_file, mat_file, pred_file, _lambda, _epsilon)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(mat_file)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(mat_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fout:\n\u001b[0;32m---> 21\u001b[0m         \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mRDIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/smm_gradient_descent.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-l\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_lambda\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-epi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_epsilon\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-e\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_file\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQT_QPA_PLATFORM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffscreen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(pred_file)\u001b[38;5;241m.\u001b[39mexists():\n",
      "File \u001b[0;32m~/anaconda3/envs/MyEnv/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/envs/MyEnv/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MyEnv/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MyEnv/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/anaconda3/envs/MyEnv/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(RDIR)\n",
    "# --- Loop over all alleles ---\n",
    "for allele in alleles:\n",
    "    make_and_enter(f\"{allele}.res\")\n",
    "\n",
    "    # --- Outer Validation loop ---\n",
    "    for n in folds:\n",
    "        inner_loop_files = [0, 1, 2, 3, 4]\n",
    "        inner_loop_files.remove(n)\n",
    "    \n",
    "        make_and_enter(f\"validation_set_{n}\")\n",
    "\n",
    "        # copy the validation files and create the new concatenated training files\n",
    "        for m in inner_loop_files:\n",
    "            # Copy the evaluation file\n",
    "            eval_file = f\"{DDIR}/{allele}/c00{m}\"\n",
    "            shutil.copy(eval_file, f\"c00{m}\")\n",
    "            # Create the concatenated trining files\n",
    "            train_files = inner_loop_files.copy()\n",
    "            train_files.remove(m)\n",
    "\n",
    "            concat_train_files(train_files, allele, DDIR, m)\n",
    "        \n",
    "        best_pcc = -1000\n",
    "        best_model = \"\"\n",
    "        best_lambda = \"\"\n",
    "        best_epsilon = \"\"\n",
    "        \n",
    "    # --- Hyperparameters loop ---    \n",
    "        for l in lambdas:\n",
    "            make_and_enter(f\"l.{l}\")\n",
    "                \n",
    "            for epi in epis:\n",
    "                make_and_enter(f\"epi.{epi}\")\n",
    "    \n",
    "                preds = []\n",
    "\n",
    "                # --- Inner CV loop ---\n",
    "                for m in inner_loop_files:\n",
    "                    \n",
    "                    # Define the files to start running\n",
    "                    mat_file = f\"mat.{m}\"\n",
    "                    pred_file = f\"c00{m}.pred\"\n",
    "                    \n",
    "                    eval_file = f\"../../c00{m}\"\n",
    "                    train_file = f\"../../conc_f00{m}\"\n",
    "                    \n",
    "                    # Run training and evalutation\n",
    "\n",
    "                    run_training_and_evaluation(RDIR, train_file, eval_file, mat_file=mat_file, pred_file=pred_file, _lambda=l, _epsilon=epi)\n",
    "                    \n",
    "                    with open(pred_file) as pf:\n",
    "                        for line in pf:\n",
    "                            if \"#\" not in line and line.strip():\n",
    "                                try:\n",
    "                                    parts = line.strip().split()\n",
    "                                    preds.append((float(parts[1]), float(parts[2])))\n",
    "                                except:\n",
    "                                    continue\n",
    "                \n",
    "                # Compute PCC and MSE\n",
    "                pcc, mse = pearson_from_pairs(preds)\n",
    "                eval_output = f\"{allele}; Outer validation set = {n}, lambda = {l} epsilon = {epi} PCC {pcc:.5f} MSE {mse:.5f}\"\n",
    "                print(eval_output)\n",
    "\n",
    "                if pcc > best_pcc:\n",
    "                    best_pcc = pcc\n",
    "                    best_lambda = l\n",
    "                    best_epsilon = epi\n",
    "                    best_model = f\"lambda {best_lambda} epsilon {best_epsilon}\"\n",
    "                    \n",
    "                \n",
    "                # Leave epi.{epi}\n",
    "                os.chdir(\"..\")\n",
    "        \n",
    "            # Leave l.{l}\n",
    "            os.chdir(\"..\")\n",
    "\n",
    "        # Final result\n",
    "        print(\"\\nBest model for allele\", allele,\"and Outer validation set '\", n, \"', :\", best_model, \"with correlation\", f\"{best_pcc:.5f}\\n\")\n",
    "\n",
    "        # Copy the final evaluation file\n",
    "        final_eval_file = f\"{DDIR}/{allele}/c00{n}\"\n",
    "        shutil.copy(final_eval_file, f\"final_evaluation_c00{n}\")\n",
    "        \n",
    "        # Copy the full training file to use when the best HP are chosen\n",
    "        full_train_file = f\"{DDIR}/{allele}/f00{n}\"\n",
    "        shutil.copy(full_train_file, f\"final_training_f00{n}\")\n",
    "\n",
    "        # Define the files to start running\n",
    "        mat_file = f\"mat.{n}\"\n",
    "        pred_file = f\"c00{n}.outer_pred\"\n",
    "                    \n",
    "        eval_file = f\"final_evaluation_c00{n}\"\n",
    "        train_file = f\"final_training_f00{n}\"\n",
    "\n",
    "        # Run training and evaluation\n",
    "        run_training_and_evaluation(RDIR, train_file, eval_file, mat_file=mat_file, pred_file=pred_file, _lambda=best_lambda, _epsilon=best_epsilon)\n",
    "        \n",
    "        # Leave validation_set_{n}\n",
    "        os.chdir(\"..\")\n",
    "\n",
    "    # Concatenate predictions for allele and get the final measure\n",
    "    collect_outer_preds(allele)\n",
    "\n",
    "    pairs = []\n",
    "    with open(f\"{allele}_prediction\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            try:\n",
    "                x = float(parts[1])  # second column\n",
    "                y = float(parts[2])  # third column\n",
    "                pairs.append((x, y))\n",
    "            except (IndexError, ValueError):\n",
    "                continue\n",
    "                \n",
    "    pcc, mse = pearson_from_pairs(pairs)\n",
    "    eval_output = f\"Final prediciton for allele:{allele}; PCC {pcc:.5f} MSE {mse:.5f}\"\n",
    "    print(eval_output)\n",
    "    \n",
    "    # Leave {allele}.res\n",
    "    os.chdir(\"..\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9cdcc-ce07-49bd-8964-6fcd4519b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main loop ---\n",
    "for allele in alleles:\n",
    "    allele_dir = Path(f\"{allele}.res\")\n",
    "    allele_dir.mkdir(exist_ok=True)\n",
    "    os.chdir(allele_dir)\n",
    "\n",
    "    for l in lambdas:\n",
    "        l_dir = Path(f\"l.{l}\")\n",
    "        l_dir.mkdir(exist_ok=True)\n",
    "        os.chdir(l_dir)\n",
    "\n",
    "        for epi in epis:\n",
    "            epi_dir = Path(f\"epi.{epi}\")\n",
    "            epi_dir.mkdir(exist_ok=True)\n",
    "            os.chdir(epi_dir)\n",
    "\n",
    "            preds = []\n",
    "\n",
    "            for n in folds:\n",
    "                mat_file = f\"mat.{n}\"\n",
    "                pred_file = f\"c00{n}.pred\"\n",
    "                train_file = f\"{DDIR}/{allele}/f00{n}\"\n",
    "                eval_file = f\"{DDIR}/{allele}/c00{n}\"\n",
    "\n",
    "                # Run training\n",
    "                if not Path(mat_file).exists():\n",
    "                    subprocess.run(\n",
    "                        [\"python\", f\"{RDIR}/smm_gradient_descent.py\",\n",
    "                         \"-l\", str(l), \"-epi\", str(epi), \"-t\", train_file, \"-e\", eval_file],\n",
    "                        stdout=open(mat_file, \"w\"),\n",
    "                        stderr=subprocess.DEVNULL,\n",
    "                        env={**os.environ, \"QT_QPA_PLATFORM\": \"offscreen\"}\n",
    "                    )\n",
    "\n",
    "                # Run evaluation\n",
    "                if not Path(pred_file).exists():\n",
    "                    with open(pred_file, \"w\") as fout:\n",
    "                        subprocess.run(\n",
    "                            [\"python\", f\"{RDIR}/pep2score.py\",\n",
    "                             \"-mat\", mat_file, \"-f\", eval_file],\n",
    "                            stdout=fout,\n",
    "                            stderr=subprocess.DEVNULL,\n",
    "                            env={**os.environ, \"QT_QPA_PLATFORM\": \"offscreen\"}\n",
    "                        )\n",
    "\n",
    "                # Parse predictions\n",
    "                with open(pred_file) as pf:\n",
    "                    for line in pf:\n",
    "                        if \"#\" not in line and line.strip():\n",
    "                            try:\n",
    "                                parts = line.strip().split()\n",
    "                                preds.append((float(parts[1]), float(parts[2])))\n",
    "                            except:\n",
    "                                continue\n",
    "\n",
    "            # Compute PCC and MSE\n",
    "            pcc, mse = pearson_from_pairs(preds)\n",
    "            eval_output = f\"{allele} lambda {l} epsilon {epi} PCC {pcc:.5f} MSE {mse:.5f}\"\n",
    "            print(eval_output)\n",
    "\n",
    "            if pcc > best_pcc:\n",
    "                best_pcc = pcc\n",
    "                best_model = f\"{allele} lambda {l} epsilon {epi}\"\n",
    "\n",
    "            os.chdir(\"..\")  # up from epi.X\n",
    "\n",
    "        os.chdir(\"..\")  # up from l.X\n",
    "\n",
    "    os.chdir(\"..\")  # up from allele.res\n",
    "\n",
    "# Final result\n",
    "print(\"\\nBest model:\", best_model, \"with correlation\", f\"{best_pcc:.5f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
